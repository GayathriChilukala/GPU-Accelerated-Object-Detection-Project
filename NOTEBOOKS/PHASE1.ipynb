{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRc8c4YSPKSP",
        "outputId": "55521cc3-7edb-44a4-8e08-787622bc8577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ENVIRONMENT VERIFICATION\n",
            "======================================================================\n",
            "Python version: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "PyTorch version: 2.8.0+cu126\n",
            "Torchvision version: 0.23.0+cu126\n",
            "CUDA available: True\n",
            "CUDA version: 12.6\n",
            "GPU Device: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "GPU-Accelerated Object Detection Pipeline - Phase 1\n",
        "Setup and Core Implementation for NVIDIA DL Project\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# PART 1: ENVIRONMENT SETUP & VERIFICATION\n",
        "# ============================================================================\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ENVIRONMENT VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check Python version\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Check PyTorch and CUDA availability\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  WARNING: CUDA not available. Using CPU.\")\n",
        "\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNlRxtvhQLbZ",
        "outputId": "f7ab525d-72e4-42e0-9321-8c628c769612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Installing required packages...\n",
            "✓ All packages imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PART 2: INSTALL DEPENDENCIES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nInstalling required packages...\")\n",
        "# Uncomment in Colab:\n",
        "# !pip install -q opencv-python-headless\n",
        "# !pip install -q albumentations\n",
        "# !pip install -q pycocotools\n",
        "# !pip install -q tensorboard\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"✓ All packages imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tWlXwgXQRB3",
        "outputId": "f1a39f6a-0c02-49e6-eb82-840d7a833491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Created 10 project directories\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PART 3: PROJECT STRUCTURE SETUP\n",
        "# ============================================================================\n",
        "\n",
        "# Create project directories\n",
        "project_dirs = [\n",
        "    'data/raw',\n",
        "    'data/processed',\n",
        "    'data/annotations',\n",
        "    'models/checkpoints',\n",
        "    'models/pretrained',\n",
        "    'outputs/images',\n",
        "    'outputs/videos',\n",
        "    'outputs/metrics',\n",
        "    'logs',\n",
        "    'notebooks'\n",
        "]\n",
        "\n",
        "for dir_path in project_dirs:\n",
        "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"✓ Created {len(project_dirs)} project directories\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djqbh5hkQVnb",
        "outputId": "4c342c3d-751f-4426-ee0c-a5d7e9326558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET SETUP - COCO 2017\n",
            "======================================================================\n",
            "Downloading val2017.zip...\n",
            "✓ Downloaded val2017.zip\n",
            "Extracting val2017.zip...\n",
            "✓ Extracted val2017.zip\n",
            "Downloading annotations_trainval2017.zip...\n",
            "✓ Downloaded annotations_trainval2017.zip\n",
            "Extracting annotations_trainval2017.zip...\n",
            "✓ Extracted annotations_trainval2017.zip\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PART 4: DATASET PREPARATION - COCO Dataset\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET SETUP - COCO 2017\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "\n",
        "def download_coco_subset():\n",
        "    \"\"\"Download COCO validation dataset (1GB vs 18GB for training)\"\"\"\n",
        "    import urllib.request\n",
        "    import zipfile\n",
        "\n",
        "    base_url = \"http://images.cocodataset.org/zips/\"\n",
        "    anno_url = \"http://images.cocodataset.org/annotations/\"\n",
        "\n",
        "    files = {\n",
        "        'val2017.zip': base_url,\n",
        "        'annotations_trainval2017.zip': anno_url\n",
        "    }\n",
        "\n",
        "    for filename, url in files.items():\n",
        "        filepath = f'data/{filename}'\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"Downloading {filename}...\")\n",
        "            urllib.request.urlretrieve(url + filename, filepath)\n",
        "            print(f\"✓ Downloaded {filename}\")\n",
        "\n",
        "            # Extract\n",
        "            print(f\"Extracting {filename}...\")\n",
        "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "                zip_ref.extractall('data/')\n",
        "            print(f\"✓ Extracted {filename}\")\n",
        "        else:\n",
        "            print(f\"✓ {filename} already exists\")\n",
        "\n",
        "download_coco_subset()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiABWLLdQnF0"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 5: CUSTOM DATASET CLASS\n",
        "# ============================================================================\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class CustomObjectDetectionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset for object detection\n",
        "    Compatible with COCO format annotations\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir, annotation_file, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Load annotations\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "\n",
        "        self.images = self.coco_data['images']\n",
        "        self.annotations = self.coco_data['annotations']\n",
        "\n",
        "        # Create image_id to annotations mapping\n",
        "        self.img_to_anns = {}\n",
        "        for ann in self.annotations:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.img_to_anns:\n",
        "                self.img_to_anns[img_id] = []\n",
        "            self.img_to_anns[img_id].append(ann)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get image info\n",
        "        img_info = self.images[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Get annotations for this image\n",
        "        img_id = img_info['id']\n",
        "        anns = self.img_to_anns.get(img_id, [])\n",
        "\n",
        "        # Extract boxes and labels\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for ann in anns:\n",
        "            # COCO format: [x, y, width, height]\n",
        "            x, y, w, h = ann['bbox']\n",
        "            # Convert to [x_min, y_min, x_max, y_max]\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(ann['category_id'])\n",
        "\n",
        "        # Convert to tensors\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': torch.tensor([img_id])\n",
        "        }\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzCNBaE3QxH6"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 6: DATA TRANSFORMS & AUGMENTATION\n",
        "# ============================================================================\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    \"\"\"Define data transforms for training and validation\"\"\"\n",
        "    if train:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((640, 640)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((640, 640)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVeO5px7Q1AB"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 7: MODEL SETUP - FASTER R-CNN WITH RESNET50 BACKBONE\n",
        "# ============================================================================\n",
        "\n",
        "import torchvision.models.detection as detection\n",
        "\n",
        "def create_model(num_classes=91, pretrained=True):\n",
        "    \"\"\"\n",
        "    Create Faster R-CNN model with ResNet50 backbone\n",
        "    num_classes: 91 for COCO (90 objects + background)\n",
        "    \"\"\"\n",
        "    # Load pretrained Faster R-CNN\n",
        "    model = detection.fasterrcnn_resnet50_fpn(pretrained=pretrained)\n",
        "\n",
        "    # Replace the classifier head for custom number of classes\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = detection.faster_rcnn.FastRCNNPredictor(\n",
        "        in_features, num_classes\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0E8hOoUQ3rO",
        "outputId": "995a9673-fde2-46b4-e82a-3355ab9ae423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION\n",
            "======================================================================\n",
            "Device: cuda\n",
            "Batch Size: 4\n",
            "Learning Rate: 0.005\n",
            "Epochs: 10\n",
            "Number of Classes: 91\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PART 8: TRAINING CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class TrainingConfig:\n",
        "    \"\"\"Configuration for training pipeline\"\"\"\n",
        "    # Dataset\n",
        "    TRAIN_IMAGE_DIR = 'data/val2017'  # Using val set for quick training\n",
        "    TRAIN_ANNO_FILE = 'data/annotations/instances_val2017.json'\n",
        "\n",
        "    # Training hyperparameters\n",
        "    BATCH_SIZE = 4\n",
        "    NUM_EPOCHS = 10\n",
        "    LEARNING_RATE = 0.005\n",
        "    MOMENTUM = 0.9\n",
        "    WEIGHT_DECAY = 0.0005\n",
        "\n",
        "    # Model\n",
        "    NUM_CLASSES = 91  # COCO has 90 classes + background\n",
        "\n",
        "    # Device\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Checkpointing\n",
        "    CHECKPOINT_DIR = 'models/checkpoints'\n",
        "    SAVE_FREQUENCY = 2  # Save every N epochs\n",
        "\n",
        "    # Logging\n",
        "    LOG_DIR = 'logs'\n",
        "    PRINT_FREQUENCY = 10  # Print every N batches\n",
        "\n",
        "config = TrainingConfig()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Device: {config.DEVICE}\")\n",
        "print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
        "print(f\"Learning Rate: {config.LEARNING_RATE}\")\n",
        "print(f\"Epochs: {config.NUM_EPOCHS}\")\n",
        "print(f\"Number of Classes: {config.NUM_CLASSES}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvSVpjK-Q7b2"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 9: TRAINING UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, loss, filename):\n",
        "    \"\"\"Save model checkpoint\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "    print(f\"✓ Checkpoint saved: {filename}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, filename):\n",
        "    \"\"\"Load model checkpoint\"\"\"\n",
        "    checkpoint = torch.load(filename)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    print(f\"✓ Checkpoint loaded from epoch {epoch}\")\n",
        "    return epoch, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfDVtk15RBzd",
        "outputId": "fea55746-2f36-4958-b210-6f2199fec9e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "QUICK MODEL TEST\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 160M/160M [00:01<00:00, 133MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on dummy image...\n",
            "✓ Model inference successful!\n",
            "  Output keys: dict_keys(['boxes', 'labels', 'scores'])\n",
            "  Number of detections: 0\n",
            "\n",
            "Model Statistics:\n",
            "  Total parameters: 41,755,286\n",
            "  Trainable parameters: 41,532,886\n",
            "  Model size: ~167.02 MB (float32)\n",
            "\n",
            "======================================================================\n",
            "✓ PHASE 1 SETUP COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Next steps:\n",
            "1. Download COCO dataset (uncomment download_coco_subset())\n",
            "2. Run the training script (coming in next artifact)\n",
            "3. Monitor training metrics\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PART 10: QUICK TEST WITH DUMMY DATA\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"QUICK MODEL TEST\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create model\n",
        "model = create_model(num_classes=config.NUM_CLASSES, pretrained=True)\n",
        "model = model.to(config.DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# Create dummy input\n",
        "dummy_image = torch.rand(1, 3, 640, 640).to(config.DEVICE)\n",
        "\n",
        "print(\"Running inference on dummy image...\")\n",
        "with torch.no_grad():\n",
        "    output = model(dummy_image)\n",
        "\n",
        "print(f\"✓ Model inference successful!\")\n",
        "print(f\"  Output keys: {output[0].keys()}\")\n",
        "print(f\"  Number of detections: {len(output[0]['boxes'])}\")\n",
        "\n",
        "# Calculate model parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel Statistics:\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Model size: ~{total_params * 4 / 1e6:.2f} MB (float32)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ PHASE 1 SETUP COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Download COCO dataset (uncomment download_coco_subset())\")\n",
        "print(\"2. Run the training script (coming in next artifact)\")\n",
        "print(\"3. Monitor training metrics\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwvD5TcQRNcN"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Training Script for GPU-Accelerated Object Detection\n",
        "Implements training loop with metrics tracking and checkpointing\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINING FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):\n",
        "    \"\"\"\n",
        "    Train for one epoch\n",
        "\n",
        "    Args:\n",
        "        model: The detection model\n",
        "        optimizer: Optimizer\n",
        "        data_loader: Training data loader\n",
        "        device: Device to train on\n",
        "        epoch: Current epoch number\n",
        "        print_freq: Print frequency\n",
        "\n",
        "    Returns:\n",
        "        Average loss for the epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "\n",
        "    loss_meter = AverageMeter()\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    # Progress bar\n",
        "    pbar = tqdm(data_loader, desc=f'Epoch {epoch}')\n",
        "\n",
        "    for batch_idx, (images, targets) in enumerate(pbar):\n",
        "        # Measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        # Move to device\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Forward pass\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        loss_meter.update(losses.item(), len(images))\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss_meter.avg:.4f}',\n",
        "            'batch_time': f'{batch_time.avg:.3f}s',\n",
        "            'data_time': f'{data_time.avg:.3f}s'\n",
        "        })\n",
        "\n",
        "        # Print detailed stats periodically\n",
        "        if (batch_idx + 1) % print_freq == 0:\n",
        "            print(f'\\nEpoch: [{epoch}][{batch_idx + 1}/{len(data_loader)}]  '\n",
        "                  f'Loss: {loss_meter.avg:.4f}  '\n",
        "                  f'Batch Time: {batch_time.avg:.3f}s  '\n",
        "                  f'Data Time: {data_time.avg:.3f}s')\n",
        "\n",
        "            # Print individual losses\n",
        "            for loss_name, loss_value in loss_dict.items():\n",
        "                print(f'  {loss_name}: {loss_value.item():.4f}')\n",
        "\n",
        "    return loss_meter.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySZ54hicRQro"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VALIDATION FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(model, data_loader, device):\n",
        "    \"\"\"\n",
        "    Validate the model\n",
        "\n",
        "    Args:\n",
        "        model: The detection model\n",
        "        data_loader: Validation data loader\n",
        "        device: Device to validate on\n",
        "\n",
        "    Returns:\n",
        "        Validation metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    loss_meter = AverageMeter()\n",
        "    inference_time = AverageMeter()\n",
        "\n",
        "    pbar = tqdm(data_loader, desc='Validation')\n",
        "\n",
        "    for images, targets in pbar:\n",
        "        # Move to device\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Measure inference time\n",
        "        start_time = time.time()\n",
        "\n",
        "        # For validation, we need to set model to train mode to get losses\n",
        "        model.train()\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        model.eval()\n",
        "\n",
        "        inference_time.update(time.time() - start_time, len(images))\n",
        "        loss_meter.update(losses.item(), len(images))\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss_meter.avg:.4f}',\n",
        "            'inference_time': f'{inference_time.avg:.3f}s'\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        'loss': loss_meter.avg,\n",
        "        'inference_time': inference_time.avg\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v-U-B9lRUZ-"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MAIN TRAINING LOOP\n",
        "# ============================================================================\n",
        "\n",
        "def train_model(model, train_loader, val_loader, config):\n",
        "    \"\"\"\n",
        "    Main training loop\n",
        "\n",
        "    Args:\n",
        "        model: The detection model\n",
        "        train_loader: Training data loader\n",
        "        val_loader: Validation data loader\n",
        "        config: Training configuration\n",
        "    \"\"\"\n",
        "    # Setup optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.SGD(\n",
        "        params,\n",
        "        lr=config.LEARNING_RATE,\n",
        "        momentum=config.MOMENTUM,\n",
        "        weight_decay=config.WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(\n",
        "        optimizer,\n",
        "        step_size=3,\n",
        "        gamma=0.1\n",
        "    )\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_inference_time': [],\n",
        "        'learning_rate': []\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STARTING TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(1, config.NUM_EPOCHS + 1):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Epoch {epoch}/{config.NUM_EPOCHS}\")\n",
        "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Training\n",
        "        train_loss = train_one_epoch(\n",
        "            model, optimizer, train_loader,\n",
        "            config.DEVICE, epoch, config.PRINT_FREQUENCY\n",
        "        )\n",
        "\n",
        "        # Validation\n",
        "        print(\"\\nRunning validation...\")\n",
        "        val_metrics = validate(model, val_loader, config.DEVICE)\n",
        "\n",
        "        # Update learning rate\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # Record history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_metrics['loss'])\n",
        "        history['val_inference_time'].append(val_metrics['inference_time'])\n",
        "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # Print epoch summary\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Epoch {epoch} Summary:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"  Val Loss: {val_metrics['loss']:.4f}\")\n",
        "        print(f\"  Val Inference Time: {val_metrics['inference_time']:.3f}s\")\n",
        "        print(f\"  Epoch Time: {epoch_time:.2f}s\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if epoch % config.SAVE_FREQUENCY == 0:\n",
        "            checkpoint_path = f\"{config.CHECKPOINT_DIR}/checkpoint_epoch_{epoch}.pth\"\n",
        "            save_checkpoint(model, optimizer, epoch, train_loss, checkpoint_path)\n",
        "\n",
        "        # Save best model\n",
        "        if val_metrics['loss'] < best_val_loss:\n",
        "            best_val_loss = val_metrics['loss']\n",
        "            best_model_path = f\"{config.CHECKPOINT_DIR}/best_model.pth\"\n",
        "            save_checkpoint(model, optimizer, epoch, val_metrics['loss'], best_model_path)\n",
        "            print(f\"✓ New best model saved! Val Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(f\"Total Training Time: {total_time/3600:.2f} hours\")\n",
        "    print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Save training history\n",
        "    history_path = f\"{config.LOG_DIR}/training_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(history_path, 'w') as f:\n",
        "        json.dump(history, f, indent=4)\n",
        "    print(f\"✓ Training history saved: {history_path}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKx4GAodRYK6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test_dataloader():\n",
        "    \"\"\"Test the data loader with a few samples\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TESTING DATA LOADER\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Create a minimal test dataset\n",
        "    # In practice, you'd use the COCO dataset\n",
        "\n",
        "    print(\"Creating data loaders...\")\n",
        "\n",
        "    # For testing, we'll create dummy data loaders\n",
        "    # Replace this with actual COCO dataset when ready\n",
        "\n",
        "    class DummyDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, num_samples=100):\n",
        "            self.num_samples = num_samples\n",
        "\n",
        "        def __len__(self):\n",
        "            return self.num_samples\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            # Dummy image\n",
        "            image = torch.rand(3, 640, 640)\n",
        "\n",
        "            # Dummy target\n",
        "            num_boxes = torch.randint(1, 10, (1,)).item()\n",
        "            boxes = torch.rand(num_boxes, 4) * 640\n",
        "            boxes[:, 2:] += boxes[:, :2]  # Ensure x2, y2 > x1, y1\n",
        "\n",
        "            target = {\n",
        "                'boxes': boxes,\n",
        "                'labels': torch.randint(1, 91, (num_boxes,)),\n",
        "                'image_id': torch.tensor([idx])\n",
        "            }\n",
        "\n",
        "            return image, target\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = DummyDataset(num_samples=100)\n",
        "    val_dataset = DummyDataset(num_samples=20)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=0,  # Set to 0 for Colab\n",
        "        collate_fn=lambda x: tuple(zip(*x))\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=lambda x: tuple(zip(*x))\n",
        "    )\n",
        "\n",
        "    print(f\"✓ Train dataset: {len(train_dataset)} samples\")\n",
        "    print(f\"✓ Val dataset: {len(val_dataset)} samples\")\n",
        "    print(f\"✓ Train batches: {len(train_loader)}\")\n",
        "    print(f\"✓ Val batches: {len(val_loader)}\")\n",
        "\n",
        "    # Test one batch\n",
        "    images, targets = next(iter(train_loader))\n",
        "    print(f\"\\nSample batch:\")\n",
        "    print(f\"  Number of images: {len(images)}\")\n",
        "    print(f\"  Image shape: {images[0].shape}\")\n",
        "    print(f\"  Target keys: {targets[0].keys()}\")\n",
        "    print(f\"  Number of boxes in first image: {len(targets[0]['boxes'])}\")\n",
        "\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mtQYzhGRk3Q",
        "outputId": "ac12e145-1390-4adf-dda5-66053b7e1270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "GPU-ACCELERATED OBJECT DETECTION - TRAINING\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TESTING DATA LOADER\n",
            "======================================================================\n",
            "Creating data loaders...\n",
            "✓ Train dataset: 100 samples\n",
            "✓ Val dataset: 20 samples\n",
            "✓ Train batches: 25\n",
            "✓ Val batches: 5\n",
            "\n",
            "Sample batch:\n",
            "  Number of images: 4\n",
            "  Image shape: torch.Size([3, 640, 640])\n",
            "  Target keys: dict_keys(['boxes', 'labels', 'image_id'])\n",
            "  Number of boxes in first image: 7\n",
            "======================================================================\n",
            "\n",
            "Creating model...\n",
            "✓ Model created and moved to cuda\n",
            "\n",
            "Starting training loop...\n",
            "(This is a quick test with dummy data)\n",
            "Replace DummyDataset with actual COCO dataset for real training\n",
            "\n",
            "\n",
            "======================================================================\n",
            "STARTING TRAINING\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Epoch 1/3\n",
            "Learning Rate: 0.005000\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  40%|████      | 10/25 [00:07<00:10,  1.38it/s, loss=2.3813, batch_time=0.782s, data_time=0.034s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: [1][10/25]  Loss: 2.3813  Batch Time: 0.782s  Data Time: 0.034s\n",
            "  loss_classifier: 0.1446\n",
            "  loss_box_reg: 0.0352\n",
            "  loss_objectness: 0.2336\n",
            "  loss_rpn_box_reg: 0.0401\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  80%|████████  | 20/25 [00:15<00:03,  1.38it/s, loss=1.7003, batch_time=0.755s, data_time=0.037s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: [1][20/25]  Loss: 1.7003  Batch Time: 0.755s  Data Time: 0.037s\n",
            "  loss_classifier: 0.1984\n",
            "  loss_box_reg: 0.0627\n",
            "  loss_objectness: 0.3151\n",
            "  loss_rpn_box_reg: 0.2702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 25/25 [00:18<00:00,  1.33it/s, loss=1.5891, batch_time=0.750s, data_time=0.036s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running validation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 5/5 [00:01<00:00,  2.88it/s, loss=0.9027, inference_time=0.306s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "Epoch 1 Summary:\n",
            "  Train Loss: 1.5891\n",
            "  Val Loss: 0.9027\n",
            "  Val Inference Time: 0.306s\n",
            "  Epoch Time: 20.49s\n",
            "======================================================================\n",
            "✓ Checkpoint saved: models/checkpoints/best_model.pth\n",
            "✓ New best model saved! Val Loss: 0.9027\n",
            "\n",
            "======================================================================\n",
            "Epoch 2/3\n",
            "Learning Rate: 0.005000\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  40%|████      | 10/25 [00:07<00:10,  1.37it/s, loss=0.6768, batch_time=0.735s, data_time=0.037s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: [2][10/25]  Loss: 0.6768  Batch Time: 0.735s  Data Time: 0.037s\n",
            "  loss_classifier: 0.2643\n",
            "  loss_box_reg: 0.0677\n",
            "  loss_objectness: 0.8826\n",
            "  loss_rpn_box_reg: 0.4382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  80%|████████  | 20/25 [00:14<00:03,  1.35it/s, loss=0.8621, batch_time=0.736s, data_time=0.036s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: [2][20/25]  Loss: 0.8621  Batch Time: 0.736s  Data Time: 0.036s\n",
            "  loss_classifier: 0.1184\n",
            "  loss_box_reg: 0.0365\n",
            "  loss_objectness: 0.2090\n",
            "  loss_rpn_box_reg: 0.0650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 25/25 [00:18<00:00,  1.36it/s, loss=0.8662, batch_time=0.736s, data_time=0.035s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running validation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 5/5 [00:01<00:00,  2.91it/s, loss=1.0337, inference_time=0.307s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "Epoch 2 Summary:\n",
            "  Train Loss: 0.8662\n",
            "  Val Loss: 1.0337\n",
            "  Val Inference Time: 0.307s\n",
            "  Epoch Time: 20.12s\n",
            "======================================================================\n",
            "✓ Checkpoint saved: models/checkpoints/checkpoint_epoch_2.pth\n",
            "\n",
            "======================================================================\n",
            "Epoch 3/3\n",
            "Learning Rate: 0.005000\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  40%|████      | 10/25 [00:07<00:11,  1.33it/s, loss=0.8834, batch_time=0.751s, data_time=0.041s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: [3][10/25]  Loss: 0.8834  Batch Time: 0.751s  Data Time: 0.041s\n",
            "  loss_classifier: 0.2004\n",
            "  loss_box_reg: 0.0685\n",
            "  loss_objectness: 0.2986\n",
            "  loss_rpn_box_reg: 0.4549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  80%|████████  | 20/25 [00:15<00:03,  1.33it/s, loss=0.9037, batch_time=0.752s, data_time=0.037s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: [3][20/25]  Loss: 0.9037  Batch Time: 0.752s  Data Time: 0.037s\n",
            "  loss_classifier: 0.2653\n",
            "  loss_box_reg: 0.1151\n",
            "  loss_objectness: 0.1390\n",
            "  loss_rpn_box_reg: 0.0648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 25/25 [00:18<00:00,  1.33it/s, loss=0.8959, batch_time=0.755s, data_time=0.039s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running validation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 5/5 [00:01<00:00,  2.85it/s, loss=1.0758, inference_time=0.315s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "Epoch 3 Summary:\n",
            "  Train Loss: 0.8959\n",
            "  Val Loss: 1.0758\n",
            "  Val Inference Time: 0.315s\n",
            "  Epoch Time: 20.64s\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "Total Training Time: 0.02 hours\n",
            "Best Validation Loss: 0.9027\n",
            "======================================================================\n",
            "✓ Training history saved: logs/training_history_20251005_151905.json\n",
            "\n",
            "✓ Training script test complete!\n",
            "Next: Replace dummy data with actual COCO dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# RUN TRAINING (QUICK TEST VERSION)\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"GPU-ACCELERATED OBJECT DETECTION - TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Setup configuration\n",
        "    config = TrainingConfig()\n",
        "    config.NUM_EPOCHS = 3  # Reduced for quick testing\n",
        "    config.BATCH_SIZE = 2  # Smaller batch for testing\n",
        "\n",
        "    # Test data loaders\n",
        "    train_loader, val_loader = test_dataloader()\n",
        "\n",
        "    # Create model\n",
        "    print(\"\\nCreating model...\")\n",
        "    model = create_model(num_classes=config.NUM_CLASSES, pretrained=True)\n",
        "    model = model.to(config.DEVICE)\n",
        "\n",
        "    print(f\"✓ Model created and moved to {config.DEVICE}\")\n",
        "\n",
        "    # Start training\n",
        "    print(\"\\nStarting training loop...\")\n",
        "    print(\"(This is a quick test with dummy data)\")\n",
        "    print(\"Replace DummyDataset with actual COCO dataset for real training\\n\")\n",
        "\n",
        "    history = train_model(model, train_loader, val_loader, config)\n",
        "\n",
        "    print(\"\\n✓ Training script test complete!\")\n",
        "    print(\"Next: Replace dummy data with actual COCO dataset\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
